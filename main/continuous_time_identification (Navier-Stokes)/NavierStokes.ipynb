{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1189e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../Utilities/')\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "import time\n",
    "from itertools import product, combinations\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from plotting import newfig, savefig\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "438eaea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(file_path):\n",
    "    all_snapshots = []\n",
    "    lines_per_snapshot = 22341\n",
    "    lines_of_garbage = 6\n",
    "    lines_per_section = lines_per_snapshot + lines_of_garbage\n",
    "    column_names = ['p', 'c', 'w', 'k', 'u', 'v', 'x', 'y']\n",
    "    snapshot_number = 0\n",
    "    for chunk in pd.read_csv(file_path, \n",
    "                             chunksize=lines_per_section,\n",
    "                             skip_blank_lines=False,\n",
    "                             names=column_names,\n",
    "                             delimiter=','):       \n",
    "        snapshot_number += 1\n",
    "        chunk['snapshot'] = None\n",
    "        data_lines = chunk.iloc[lines_of_garbage:].copy()\n",
    "        if (len(data_lines)==0):break\n",
    "        print(f\"Loading snapshot {snapshot_number}/100, Length: {len(data_lines)}\", end='\\r', flush=True)\n",
    "        data_lines['t'] = snapshot_number\n",
    "        all_snapshots.append(data_lines)\n",
    "    all_data = pd.concat(all_snapshots, ignore_index=True)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9413cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ecaaf790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedNN:\n",
    "    # Initialize the class\n",
    "    def __init__(self, x, y, t, wind, leak_x, leak_y, leak_s, u, v, c, k, w, layers):        \n",
    "        X = np.concatenate([x, y, t, wind, leak_x, leak_y, leak_s], 1)\n",
    "        \n",
    "        self.lb = X.min(0)\n",
    "        self.ub = X.max(0)\n",
    "                \n",
    "        self.X = X\n",
    "        \n",
    "        self.x = X[:,0:1]\n",
    "        self.y = X[:,1:2]\n",
    "        self.t = X[:,2:3]\n",
    "        self.wind = X[:,3:4]\n",
    "        self.leak_s = X[:,4:5]\n",
    "        self.leak_x = X[:,5:6]\n",
    "        self.leak_y = X[:,6:7]\n",
    "    \n",
    "        self.u = u\n",
    "        self.v = v\n",
    "        self.c = c\n",
    "        self.k = k\n",
    "        self.w = w\n",
    "        \n",
    "        self.layers = layers\n",
    "        \n",
    "        # Initialize NN\n",
    "        self.weights, self.biases = self.initialize_NN(layers)        \n",
    "        \n",
    "        # Define and Initialize parameters\n",
    "        #self.rho = tf.Variable([0.0], dtype=tf.float32)\n",
    "        #self.lambda_2 = tf.Variable([0.0], dtype=tf.float32)\n",
    "        \n",
    "        # tf placeholders and graph\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                                     log_device_placement=False))\n",
    "             \n",
    "        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]]) #self.x.shape[1] is 1\n",
    "        self.y_tf = tf.placeholder(tf.float32, shape=[None, self.y.shape[1]])\n",
    "        self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t.shape[1]])\n",
    "        self.wind_tf = tf.placeholder(tf.float32, shape=[None, self.wind.shape[1]])\n",
    "        self.leak_x_tf = tf.placeholder(tf.float32, shape=[None, self.leak_x.shape[1]])\n",
    "        self.leak_y_tf = tf.placeholder(tf.float32, shape=[None, self.leak_y.shape[1]])\n",
    "        self.leak_s_tf = tf.placeholder(tf.float32, shape=[None, self.leak_s.shape[1]])\n",
    "        \n",
    "        self.u_tf = tf.placeholder(tf.float32, shape=[None, self.u.shape[1]])\n",
    "        self.v_tf = tf.placeholder(tf.float32, shape=[None, self.v.shape[1]])\n",
    "        self.c_tf = tf.placeholder(tf.float32, shape=[None, self.c.shape[1]])\n",
    "        self.k_tf = tf.placeholder(tf.float32, shape=[None, self.k.shape[1]])\n",
    "        self.w_tf = tf.placeholder(tf.float32, shape=[None, self.w.shape[1]])\n",
    "         \n",
    "        self.u_pred, self.v_pred, self.c_pred, self.k_pred, self.w_pred, self.f_continuity, self.f_convection =\\\n",
    "            self.net_NS(self.x_tf, self.y_tf, self.t_tf, self.wind_tf, self.leak_x_tf, self.leak_y_tf, self.leak_s_tf)\n",
    "\n",
    "#         self.loss = tf.reduce_sum(tf.square(self.u_tf - self.u_pred)) + \\\n",
    "#                     tf.reduce_sum(tf.square(self.v_tf - self.v_pred)) + \\\n",
    "#                     tf.reduce_sum(tf.square(self.c_tf - self.c_pred)) + \\\n",
    "#                     tf.reduce_sum(tf.square(self.k_tf - self.k_pred)) + \\\n",
    "#                     tf.reduce_sum(tf.square(self.w_tf - self.w_pred)) + \\\n",
    "#                     tf.reduce_sum(tf.square(self.f_continuity)) + \\\n",
    "#                     tf.reduce_sum(tf.square(self.f_convection))\n",
    "        self.loss = tf.reduce_sum(tf.square(self.u_tf - self.u_pred))\n",
    "    \n",
    "    \n",
    "        self.closs = tf.reduce_sum(tf.square(self.c_tf - self.c_pred)) # not used in trainig\n",
    "                    \n",
    "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
    "                                                                method = 'L-BFGS-B', \n",
    "                                                                options = {'maxiter': 50000,\n",
    "                                                                           'maxfun': 50000,\n",
    "                                                                           'maxcor': 50,\n",
    "                                                                           'maxls': 50,\n",
    "                                                                           'ftol' : 1.0 * np.finfo(float).eps}) \n",
    "        self.train_op_BFGS = self.optimizer.minimize(self.loss)\n",
    "        \n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)                    \n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "        \n",
    "    def initialize_NN(self, layers):        \n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers) \n",
    "        for l in range(0,num_layers-1):\n",
    "            #W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            W = tf.Variable(tf.zeros([layers[l],layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)        \n",
    "        return weights, biases\n",
    "    \n",
    "    def xavier_init(self, size): #other name: Glorot\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]        \n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "    \n",
    "    def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "        # maping all variables to [-1,1]\n",
    "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0  \n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "    \n",
    "    def net_NS(self, x, y, t, wind, leak_x, leak_y, leak_s):\n",
    "        # Concatenating all input variables\n",
    "        input_data = tf.concat([x, y, t, wind, leak_x, leak_y, leak_s], 1)\n",
    "\n",
    "\n",
    "        u_v_c_k_w = self.neural_net(input_data, self.weights, self.biases)\n",
    "        u = u_v_c_k_w[:,0:1]\n",
    "        v = u_v_c_k_w[:,1:2]\n",
    "        c = u_v_c_k_w[:,2:3]\n",
    "        k = u_v_c_k_w[:,3:4]\n",
    "        w = u_v_c_k_w[:,4:5]\n",
    "    \n",
    "        # Calculating the required derivatives\n",
    "        u_x = tf.gradients(u, x)[0]\n",
    "        v_y = tf.gradients(v, y)[0]\n",
    "        c_x = tf.gradients(c, x)[0]\n",
    "        c_y = tf.gradients(c, y)[0]\n",
    "        c_t = tf.gradients(c, t)[0]\n",
    "        c_xx = tf.gradients(c_x, x)[0]\n",
    "        c_yy = tf.gradients(c_y, y)[0]\n",
    "        \n",
    "        f_continuity = u_x + v_y\n",
    "        #f_convection = self.compute_f_convection(u, v, c, k, w, u_x, v_y, c_x, c_y, c_t, c_xx, c_yy)\n",
    "        f_convection =  u_x + v_y\n",
    "\n",
    "        return u, v, c, k, w, f_continuity, f_convection \n",
    "\n",
    "    def compute_f_convection(self, u, v, c, k, w, u_x, v_y, c_x, c_y, c_t, c_xx, c_yy):\n",
    "        transient_term = c_t\n",
    "        convective_term =  u*c_x + v*c_y # assuming c * (u_x + v_y) is zero or continuity is satisfied\n",
    "        diffusive_term = (1.7e-05 + (2.08e-5*k / w) / 0.803) * (c_xx + c_yy)\n",
    "        summation = transient_term + convective_term + diffusive_term     \n",
    "        return summation\n",
    "    \n",
    "    def callback(self, loss):\n",
    "        print('Loss: %.3e, Concentraion loss: %.3e' % (loss))\n",
    "      \n",
    "    def train(self, nIter): \n",
    "        tf_dict = {self.x_tf: self.x, self.y_tf: self.y, self.t_tf: self.t, self.wind_tf: self.wind,\n",
    "                   self.leak_x_tf: self.leak_x, self.leak_y_tf: self.leak_y, self.leak_s_tf: self.leak_s,\n",
    "                   self.u_tf: self.u, self.v_tf: self.v, self.c_tf: self.c,\n",
    "                   self.k_tf: self.k, self.w_tf: self.w}\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "            #self.sess.run(self.train_op_BFGS, tf_dict)\n",
    "            \n",
    "            # Print\n",
    "            if it % 1 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                loss_value = self.sess.run(self.loss, tf_dict)\n",
    "                closs_value = self.sess.run(self.closs, tf_dict)\n",
    "\n",
    "                #lambda_1_value = self.sess.run(self.lambda_1)\n",
    "                #lambda_2_value = self.sess.run(self.lambda_2)\n",
    "                print('It: %d, Loss: %.3e, cLoss: %.3e, Time: %.2f' % \n",
    "                      (it, loss_value,closs_value, elapsed))\n",
    "                start_time = time.time()\n",
    "           \n",
    "        self.optimizer.minimize(self.sess,\n",
    "                                feed_dict = tf_dict,\n",
    "                                fetches = [self.loss],\n",
    "                                loss_callback = self.callback)\n",
    "            \n",
    "#     def predict(self, x_star, y_star, t_star, wind_star, leak_x_star, leak_y_star, leak_s_star):\n",
    "#         tf_dict = {self.x_tf: x_star, self.y_tf: y_star, self.t_tf: t_star, self.wind_tf: wind_star,\n",
    "#                    self.leak_x_tf: leak_x_star, self.leak_y_tf: leak_y_star, self.leak_s_tf: leak_s_tf}\n",
    "#         u_star = self.sess.run(self.u_pred, tf_dict)\n",
    "#         v_star = self.sess.run(self.v_pred, tf_dict)\n",
    "#         c_star = self.sess.run(self.p_pred, tf_dict)\n",
    "#         return u_star, v_star, c_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "921bc51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=\"/input/data/nmh.csv\"\n",
    "#data = load_csv(file_path).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "77ac8f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 02:48:33.685516: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-14 02:48:33.685612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: Quadro RTX 6000 major: 7 minor: 5 memoryClockRate(GHz): 1.77\n",
      "pciBusID: 0000:17:00.0\n",
      "2023-10-14 02:48:33.686174: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-14 02:48:33.686195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 1 with properties: \n",
      "name: Quadro RTX 6000 major: 7 minor: 5 memoryClockRate(GHz): 1.77\n",
      "pciBusID: 0000:73:00.0\n",
      "2023-10-14 02:48:33.686824: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:a6:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-14 02:48:33.686910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 2 with properties: \n",
      "name: Quadro RTX 6000 major: 7 minor: 5 memoryClockRate(GHz): 1.77\n",
      "pciBusID: 0000:a6:00.0\n",
      "2023-10-14 02:48:33.686987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-10-14 02:48:33.687101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-10-14 02:48:33.687151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-10-14 02:48:33.687186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-10-14 02:48:33.687220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-10-14 02:48:33.687254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-10-14 02:48:33.687289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-10-14 02:48:33.688239: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-14 02:48:33.689020: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-14 02:48:33.689650: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:a6:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-14 02:48:33.690499: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-14 02:48:33.691634: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-14 02:48:33.692288: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:a6:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-14 02:48:33.692366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0, 1, 2\n",
      "2023-10-14 02:48:33.692518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-10-14 02:48:33.692547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 1 2 \n",
      "2023-10-14 02:48:33.692573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N N N \n",
      "2023-10-14 02:48:33.692593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 1:   N N N \n",
      "2023-10-14 02:48:33.692612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 2:   N N N \n",
      "2023-10-14 02:48:33.694140: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-14 02:48:33.694287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-14 02:48:33.694826: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-14 02:48:33.694853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Could not identify NUMA node of platform GPU id 1, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-14 02:48:33.695310: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:a6:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-14 02:48:33.695333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Could not identify NUMA node of platform GPU id 2, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-14 02:48:33.695877: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-14 02:48:33.695930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22147 MB memory) -> physical GPU (device: 0, name: Quadro RTX 6000, pci bus id: 0000:17:00.0, compute capability: 7.5)\n",
      "2023-10-14 02:48:33.696632: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-14 02:48:33.696818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 22147 MB memory) -> physical GPU (device: 1, name: Quadro RTX 6000, pci bus id: 0000:73:00.0, compute capability: 7.5)\n",
      "2023-10-14 02:48:33.697400: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:a6:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-14 02:48:33.697475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 22147 MB memory) -> physical GPU (device: 2, name: Quadro RTX 6000, pci bus id: 0000:a6:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [96]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m leak_s_train \u001b[38;5;241m=\u001b[39m leak_s[idx,:]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPhysicsInformedNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwind_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mleak_x_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleak_y_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleak_s_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mu_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;241m21\u001b[39m)\n",
      "Input \u001b[0;32mIn [94]\u001b[0m, in \u001b[0;36mPhysicsInformedNN.__init__\u001b[0;34m(self, x, y, t, wind, leak_x, leak_y, leak_s, u, v, c, k, w, layers)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcloss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(tf\u001b[38;5;241m.\u001b[39msquare(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_tf \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_pred)) \u001b[38;5;66;03m# not used in trainig\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcontrib\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mScipyOptimizerInterface(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \n\u001b[1;32m     70\u001b[0m                                                         method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     71\u001b[0m                                                         options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m50000\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m                                                                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxls\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     75\u001b[0m                                                                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mftol\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39meps}) \n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_op_BFGS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_Adam \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mAdamOptimizer()\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_op_Adam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_Adam\u001b[38;5;241m.\u001b[39mminimize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss)                    \n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_core/contrib/opt/python/training/external_optimizer.py:170\u001b[0m, in \u001b[0;36mExternalOptimizerInterface.minimize\u001b[0;34m(self, session, feed_dict, fetches, step_callback, loss_callback, **run_kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    143\u001b[0m              session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    144\u001b[0m              feed_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m              loss_callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    148\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrun_kwargs):\n\u001b[1;32m    149\u001b[0m   \u001b[38;5;124;03m\"\"\"Minimize a scalar `Tensor`.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m  Variables subject to optimization are updated in-place at the end of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m    **run_kwargs: kwargs to pass to `session.run`.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m   session \u001b[38;5;241m=\u001b[39m session \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mget_default_session()\n\u001b[1;32m    171\u001b[0m   feed_dict \u001b[38;5;241m=\u001b[39m feed_dict \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    172\u001b[0m   fetches \u001b[38;5;241m=\u001b[39m fetches \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/ops.py:765\u001b[0m, in \u001b[0;36mTensor.__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    748\u001b[0m   \u001b[38;5;124;03m\"\"\"Dummy method to prevent a tensor from being used as a Python `bool`.\u001b[39;00m\n\u001b[1;32m    749\u001b[0m \n\u001b[1;32m    750\u001b[0m \u001b[38;5;124;03m  This overload raises a `TypeError` when the user inadvertently\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;124;03m    `TypeError`.\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 765\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_disallow_bool_casting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/ops.py:534\u001b[0m, in \u001b[0;36mTensor._disallow_bool_casting\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    530\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disallow_when_autograph_enabled(\n\u001b[1;32m    531\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing a `tf.Tensor` as a Python `bool`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    533\u001b[0m   \u001b[38;5;66;03m# Default: V1-style Graph execution.\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_disallow_in_graph_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing a `tf.Tensor` as a Python `bool`\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/ops.py:521\u001b[0m, in \u001b[0;36mTensor._disallow_in_graph_mode\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_disallow_in_graph_mode\u001b[39m(\u001b[38;5;28mself\u001b[39m, task):\n\u001b[0;32m--> 521\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOperatorNotAllowedInGraphError(\n\u001b[1;32m    522\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is not allowed in Graph execution. Use Eager execution or decorate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    523\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m this function with @tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(task))\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "      \n",
    "    #N_train = 5000\n",
    "    N_train = 2\n",
    "    \n",
    "    #layers = [7, 20, 20, 20, 20, 20, 20, 20, 20, 5]\n",
    "    layers = [7, 5]\n",
    "    \n",
    "    x = np.array(data['x']).flatten()[:,None]\n",
    "    y = np.array(data['y']).flatten()[:,None]\n",
    "    t = np.array(data['t']).flatten()[:,None]\n",
    "    u = np.array(data['u']).flatten()[:,None]\n",
    "    v = np.array(data['v']).flatten()[:,None]\n",
    "    c = np.array(data['c']).flatten()[:,None]\n",
    "    k = np.array(data['k']).flatten()[:,None]\n",
    "    w = np.array(data['w']).flatten()[:,None]\n",
    "    wind = np.full_like(x, 9) # wind speed\n",
    "    leak_x = np.full_like(x, 0)\n",
    "    leak_y = np.full_like(x, 1)\n",
    "    leak_s = np.full_like(x, 1) # leak speed\n",
    "\n",
    "    # Training Data    \n",
    "    idx = np.random.choice(len(x), N_train, replace=False)\n",
    "    x_train = x[idx,:]\n",
    "    y_train = y[idx,:]\n",
    "    t_train = t[idx,:]\n",
    "    u_train = u[idx,:]\n",
    "    v_train = v[idx,:]\n",
    "    c_train = c[idx,:]\n",
    "    k_train = k[idx,:]\n",
    "    w_train = w[idx,:]\n",
    "    wind_train = wind[idx,:]\n",
    "    leak_x_train = leak_x[idx,:]\n",
    "    leak_y_train = leak_y[idx,:]\n",
    "    leak_s_train = leak_s[idx,:]\n",
    "\n",
    "    # Training\n",
    "    model = PhysicsInformedNN(x_train, y_train, t_train, wind_train,\n",
    "                              leak_x_train, leak_y_train, leak_s_train,\n",
    "                              u_train, v_train, c_train, k_train, w_train, layers)\n",
    "    \n",
    "    model.train(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ee1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Test Data\n",
    "    snap = np.array([100])\n",
    "    x_star = X_star[:,0:1]\n",
    "    y_star = X_star[:,1:2]\n",
    "    t_star = TT[:,snap]\n",
    "    \n",
    "    u_star = U_star[:,0,snap]\n",
    "    v_star = U_star[:,1,snap]\n",
    "    p_star = P_star[:,snap]\n",
    "    \n",
    "    # Prediction\n",
    "    u_pred, v_pred, p_pred = model.predict(x_star, y_star, t_star, wind_star, leak_star, angle_star)\n",
    "    lambda_1_value = model.sess.run(model.lambda_1)\n",
    "    lambda_2_value = model.sess.run(model.lambda_2)\n",
    "    \n",
    "    # Error\n",
    "    error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "    error_v = np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2)\n",
    "    error_p = np.linalg.norm(p_star-p_pred,2)/np.linalg.norm(p_star,2)\n",
    "\n",
    "    error_lambda_1 = np.abs(lambda_1_value - 1.0)*100\n",
    "    error_lambda_2 = np.abs(lambda_2_value - 0.01)/0.01 * 100\n",
    "    \n",
    "    print('Error u: %e' % (error_u))    \n",
    "    print('Error v: %e' % (error_v))    \n",
    "    print('Error p: %e' % (error_p))    \n",
    "    print('Error l1: %.5f%%' % (error_lambda_1))                             \n",
    "    print('Error l2: %.5f%%' % (error_lambda_2))                  \n",
    "    \n",
    "    # Plot Results\n",
    "#    plot_solution(X_star, u_pred, 1)\n",
    "#    plot_solution(X_star, v_pred, 2)\n",
    "#    plot_solution(X_star, p_pred, 3)    \n",
    "#    plot_solution(X_star, p_star, 4)\n",
    "#    plot_solution(X_star, p_star - p_pred, 5)\n",
    "    \n",
    "    # Predict for plotting\n",
    "    lb = X_star.min(0)\n",
    "    ub = X_star.max(0)\n",
    "    nn = 200\n",
    "    x = np.linspace(lb[0], ub[0], nn)\n",
    "    y = np.linspace(lb[1], ub[1], nn)\n",
    "    X, Y = np.meshgrid(x,y)\n",
    "    \n",
    "    UU_star = griddata(X_star, u_pred.flatten(), (X, Y), method='cubic')\n",
    "    VV_star = griddata(X_star, v_pred.flatten(), (X, Y), method='cubic')\n",
    "    PP_star = griddata(X_star, p_pred.flatten(), (X, Y), method='cubic')\n",
    "    P_exact = griddata(X_star, p_star.flatten(), (X, Y), method='cubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dc2c4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_solution(X_star, u_star, index):\n",
    "    \n",
    "    lb = X_star.min(0)\n",
    "    ub = X_star.max(0)\n",
    "    nn = 200\n",
    "    x = np.linspace(lb[0], ub[0], nn)\n",
    "    y = np.linspace(lb[1], ub[1], nn)\n",
    "    X, Y = np.meshgrid(x,y)\n",
    "    \n",
    "    U_star = griddata(X_star, u_star.flatten(), (X, Y), method='cubic')\n",
    "    \n",
    "    plt.figure(index)\n",
    "    plt.pcolor(X,Y,U_star, cmap = 'jet')\n",
    "    plt.colorbar()\n",
    "    \n",
    "def axisEqual3D(ax):\n",
    "    extents = np.array([getattr(ax, 'get_{}lim'.format(dim))() for dim in 'xyz'])\n",
    "    sz = extents[:,1] - extents[:,0]\n",
    "    centers = np.mean(extents, axis=1)\n",
    "    maxsize = max(abs(sz))\n",
    "    r = maxsize/4\n",
    "    for ctr, dim in zip(centers, 'xyz'):\n",
    "        getattr(ax, 'set_{}lim'.format(dim))(ctr - r, ctr + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a75ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
